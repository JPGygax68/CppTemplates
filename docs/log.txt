2014-10-01
==========

Thoughts about updatable templates
----------------------------------

After trying to come up with algorithms by myself, and searching for a bit for C++ libraries providing diffing/merging functionality, and came back to the more pragmatic idea of using Git itself for the task of updating existing code.

The idea is simply this:

- When first running the code generator, the generator stores all parameters so it can later re-generate on the same basis.

- Immediately after generating the very first version of the code (unmodified by the user), the generator creates a new special "skeleton" branch in the git repository (which it may have to create itself), to which it commits this "newborn" version. (It then switches back to the previously selected branch.)  [Note: the (hidden?) file containing the template parameters should also be committed to make sure it will there for re-runs - see below.]

- The user works on the obtained skeleton, modifying and extending it as he sees fit.

- When an updated version of the template becomes available, the user can issue a command that downloads (or otherwise obtains) the newest version of the template and re-generates the skeleton code, which it commits to the "skeleton" branch as a new commit.

- That command then immediately starts a merge operation from the skeleton branch to the development branch. (That merge operation may or may not run to completion; if conflicts arise that cannot be resolved automatically, the user will have to reconcile the conflicts himself, the same way he would with a merge between ordinary branches.)

It is difficult to appraise how difficult the skeleton-to-development branch merges would be. Current diff'ing/merging algorithms are line-based and unaware of a source file's semantics (exception: http://www.semanticmerge.com/), and know even less of the relationship between a template and the code that was generated from it. Nevertheless, the approach seems at least worth a try.

As for the templating engine, as I noted before, "plustache" seems a good basis. There is no command-line version of this, but that should be relatively easy to code (except for the part handling directory structures), and CMake could be used to build it on the development platform. The right moment to do this would be when installing (or packaging) CppTemplates itself; this means that CppTemplates would need to be put on CMake's shoulders itself.

All in all, this could well mean that the days of CMD-specific test scripts could soon be over; with CMake making an entrance and quite some coding ahead, adding a little more for testing doesn't seem so far out.

Unless, of course, the template command line becomes a project of its own.

And, oh, how about making that file-system based templating (meta-?) engine into a library with an *optional* command line interface ?

*Sigh* Things are never simple, are they...


2014-09-30
==========

- Possible TODO: automatically generate a test source file for every header file ?

2014-09-29
==========

I haven't yet tried to create (and use) a library that has a "top-level" header file, i.e. one is intended to represent the whole of the lowest-level namespace instead of being a component inside it.

This should probably be made into a template feature.

2014-09-23
==========

Having asked yesterday's question on StackOverflow (question 25983741), and obtained an answer - from ComicSansMS again! -, I decided to remove the NAMESPACE feature from my template. I think that doing so made using the template quite a bit simpler.

One question that remains open at this point is whether or not CMake would ensure that the "lib" prefix gets prepended to shared object names on Linux. My CMakeLists.txt template strips the initial "lib" from the project name (where it is now mandatory) to derive the target name, which leads to correctly named .dll and .lib (import) filenames on Windows; but I'm not sure whether it gets re-attached under Linux by default, or if I need to take measures to ensure that myself.

2014-09-22
==========

I've just hit a snag. It seems that CMake does not support having any correspondence between the namespace of an exported or installed target and the name of the generated library file.

So, for example, CMake makes it easy to create packages that contain unambiguously named targets such as "MyOrg::MyLibrary" (using the NAMESPACE options of the export(EXPORT ...) and install(EXPORT ...) commands, but the actual .a, .lib, .so, or .dll files would still globally-spaced names such as "libMyLibrary.a".

It is of course possible to apply namespaces to your targets yourself; in the above example, you could name your target MyOrgMyLibrary, leading to a library filename such as "libMyOrgMyLibrary.a". Which is ok I guess, except that this makes the NAMESPACE option essentially useless (or you'd end up with targets named "MyOrg::MyOrgMyLibrary"), making me think that I'm missing something.

Is there a way to override the name of a generated library ? Or what would be the "right" way to ensure your library files get unambiguous names with CMake ?

2014-09-21
==========

Today I had to change - again - the way package and target names are used. This topic touches upon broader questions, so I'll try to do a little brain dump here:

A package should contain exactly one software "item". This can be a "library" - though the term turns out to be misleading if that rule is obeyed! -, an executable tool, or an application.

A reflection on the term "library" seems appropriate here. 

I think the term originally referred to a "collection of functions", such as Fortran or C programmers would create back in the early days of programming. The term seems a bit less intuitive when the software is object-oriented, though I suppose it could be re-interpreted to mean "collection of functions and/or classes".

Now, with the stated goal of having "atomic" software modules, the term becomes even less intuitive - can a library contain a single class and still be called a library ? Should the goal of having atomic modules be questioned again ? 

The argument in defense of traditional, "bigger" modules goes like this: a library can contain as many books as it likes, a user of that library is still free to use only those books he is interested in.

The flaw in the argument is the subtle misunderstanding of the term "library". Back when a library was a relatively small module containing a handful of functions, the library/book analogy was accurate enough; even if the library header contained a few definitions use by more than a single function, application code could indeed use a single function out of the set without incurring any negative side effects.

Today however, there are many libraries that cannot be used like that, simply because they were not created to be repositories of reusable code but rather implementations of specific and often complex and interdependent functionality managing their own state - in other words, APIs. The difference between the two being fluid, no-one ever cared to create a new term to replace the overstrained word "library" - other than perhaps "module", which is alas even more overused.

So, the idea of "atomic modules" is probably just a "return to origins". It will not remove the need for "bigger" modules, but can hopefully lessen it a bit.

----------------

A problem that can come with a lot of small modules is that of name clashes. In the C++ language itself, those can be avoided by using namespaces. Unfortunately, that mechanism does not help with the generated library files (.a, .so, .lib, .dll) - there are quite a few examples of libraries that have names that are not actually identical, but very easy to confuse.

Java has dealt with this problem rather decisively. But I don't think the principle Java uses (URL components in reverse) should be applied to the C++ world. Not that it couldn't work; but the fact that, in C++, a given module nearly always requires more than one file (header and "object" or "lib" file) makes this principle unwieldy. And, more importantly, C++ simply lacks a standardized way of packaging modules.

I think the best shot is the one I've been pursuing so far: letting the developer handle both namespaces and a "prefix" that is intended as a "mini-namespace" to help the generated library file(s) (if any) maintain their identity in the basically flat namespace that is created by a system's include/ and lib/ directories.

So, the next TODO is to apply the prefix I've (re-)introduced today to generated library files.

Also, I think I should abandon the idea of deriving the prefix from the namespace at all costs - arbitrary long strings of acronyms will not help making files easier to identify. Though I suppose that single-level namespaces are ok.

There is more reflecting to be done on this subject; I wonder if I should explicitly support Boost's way of naming library files ? I'm afraid I will have to do just that - it's the only way to avoid problems stemming from incompatible compilers / runtime libraries. (Actually, the system should even be extensible so it can include further build options.)





2014-09-18 (night)
==================

- TODO: Use "install" that is specific to the test (stage directory) to avoid accidental cross-use ?


2014-09-17
==========

A few thoughts about templates:

- Multi-file templating:
  
  - Filenames should accept placeholders that can change not only the name of the produced file(s), but also their location (i.e. the placeholder can potentially be replaced with a folder hierarchy instead of just a string. [This should not be too difficult if the generated files are treated as a flat list rather than a tree.]
  
  - Every template file could generate zero, one or several instances.
  
  - Re-instancing the same version of a template with different parameters can add, move, or delete files, in addition to modifying their content
  
  - Re-instancing a new version of a template with the same parameters can do the same, and additionally lead to "orphaned" files.
  
  - Updating the template and changing the parameters should never be done in a single operation.
  
- Parameters:
  
  - The parameters should be collected in the form of a "response file".
  
  - Ideally, the responses would be named, not purely sequential; they could thus be considered parameters rather than just responses.
  
  - This is stuff for a separate library ["GPCResponses"].
  
  
2014-09-16
==========

Have begun making my template fit for header-only libraries. I copied the test scripts and now have basically two "sub" test suites, one for building a shared library and one for building a header-only one (static still pending).

The present problem is that I bumped into the need (or wish) for using templating, because the declspec() attributes of MSVC turn out to be incompatible with header-only libraries. 

While it would be easy to make the corresponding preprocessor code conditional, this is fairly ugly for code that has no chance of ever being built as a shared library.

In fact, there is a high-level decision to be taken here: should the library template support converting the library to a different type after the scaffolding, or should it try to remove all unnecessary code so the programmer only gets what he needs?

The latter approach is the one that would require templating, while generating preprocessor definitions from CMakeLists.txt would probably be sufficient for the former.

I shall go with the former approach, at least for now (starting tomorrow). If support is to be added later on for cleaning up unneeded code sections, Google's CTemplate seems to be a usable library, as is the C++ Mustache port that can be found here: https://github.com/mrtazz/plustache .


2014-09-13
==========

Ok! Some success at least, let's step back and see what I've accomplished.

I have a "Library" template that I've put under the control of a set of test scripts.

The template itself is small: all it contains is header file that defines a single class with a single method; a source file implementing that method; the source for a test suite executable; and a CMakeLists.txt file controlling the whole.

The real value though comes from the test scripts. Those are presently implemented as Windows CMD batches only, and cover the following functionality:

- The template can be used to build a (shared) library.
 
- That library can be found by CMake without installing (that is, it can be used from the build tree).

- The library can be linked with a CMake target of type "executable".

- The test suite will report a failure before an (artificial) "bug" is "fixed".

- The test suite will report success after that bug is fixed.

- The library can be found by CMake once it has been installed and its build tree deleted.

I think the template might be usable in its present form, though there are lots of things I haven't implemented or even though about yet:

- I'm not testing debug and release builds.

- I haven't even manually tested creating a static library instead of a shared one; but I'd like to test that option using the same set of scripts (meaning I'd have to introduce parameters).

- There is no support for custom build tools (such as GPCBin2C) in the CMakeLists.txt template. 
  (Not sure how I would go about testing that.)

- No support for a generated/templatized config header (e.g. mylib_config.h).

- There is no support for a configurable top-level namespace (such as Boost has).

- There is no support for a sample/demo program.

- There is no LICENSE or README file.

- The test suite template is very simple and does not contain any code snippets.

- There is only one template so far, the one for libraries. I need to be able to create executable projects too.

2014-09-06
==========

Yet another new project: GPC C++ templates.

The goal is to make it dead easy to create new portable C++ software, be it libraries (static or shared), tools, or applications.

This is supposed to be a long-term effort, and is a serious undertaking, which means that the templates, any accompanying tools, etc., must come with test cases. An untested feature is not a feature.

The whole template library shall be test-driven, so the first task is to get a test system going along with the first template, which shall be a C++ library.

I'm hesitating as to how to implement the scripting (i.e. how to run the tests). I'm seriously considering doing this in C++ all the way through. The alternatives are unattractive: bash is great for scripting, but not there under Windows; other scripting tools like Python, Node etc. are also great, but are serious products of their own travelling with their own luggage.

Before taking that decision, what exactly do I need ? Fortunately, not much at all:

- I need to be able to run the test suites for each of the templates (each template will have its own test suite), and determine whether they ran successfully or not.

That's about it. Thinking about it, CMake is all I really need (plus maybe a bootstrap one-liner in bash + cmd).

-> Hm. CMake seems to generate project and solution files even when the only command is message("Hello world"). Investigating...
  - Came across "ProjectGenerator". Am gonna give it a shot, looks like an alternative to this whole templates business.
    ... well, maybe not after all. But I have the downloaded zip ready just in case.

-> Batch files it is, for now at least. They should, must, remain super-simple though.

- I think SED (Stream EDitor) is the answer to generating test cases.

-----

Some success! I have built a test script that takes a super-simple template, does a very small bit of customization, then calls CMake to build and install.

Much remains to do: 

- Testing the results:
  - Can the library's build tree be found ?
  - Can it be used from its installed location ?
  - Does the package correctly report its name (with namespace) and version ?

- Add tests as part of the template, and test that part of the functionality as well.
  
- Support for additional components
